---
title: "Unit 7 RTorch"
output: html_notebook
---

# Tensoren
Um mit Tensoren zu arbeiten, müssen Sie zunächst das Package installieren und laden:
```{r}
if (!require("torch")) install.packages("torch")
library(torch)
```

Erstellen Sie direkt Ihren ersten Tensor in Form einer Matrix:
```{r}
torch_tensor(matrix(1:9, ncol=3))
```

Sie können Tensoren untersuchen und deren Eigenschaften bearbeiten:
```{r}
t2 <- t1$to(dtype = torch_int())
t2$dtype
```

Sie können auch vordefinierte Tensoren erstellen:
```{r}
torch_eye(n =5)
```

Tensoren können aus Datensätzen erstellt werden:
```{r}
torch_tensor(JohnsonJohnson)
```

Gegebenenfalls müssen characters erst in Faktoren, dann Numerics überführt werden und daraus dann ein Tensor erstellt werden.


Sie können mit Tensoren rechnen
Addition
```{r}
t1 <- torch_tensor(c(1, 2))
t2 <- torch_tensor(c(3, 4))

torch_add(t1, t2)
```

Kreuzprodukt
```{r}
t1 <- torch_tensor(c(2,7,1))
t2 <- torch_tensor(c(8,2,8))
t1$dot(t2)
```

Matrixmultiplikation
```{r}
t1 <- torch_tensor(1:3)
t2 <- torch_tensor(4:6)
t3 <- torch_tensor(matrix(1:12, ncol = 3, byrow = TRUE))
t3$matmul(t1)
```

Skalarprodukt
```{r}
torch_multiply(t1, t2)
```

Schließlich können Sie Summary Operations benutzen. Sie können entweder die ganze Matrix oder nur Zeilen oder nur Spalten einbeziehen (Dimension)

```{r}
t <- torch_outer(torch_tensor(1:3), torch_tensor(1:6))
t$sum()
```

```{r}
t$sum(dim = 1)
```

```{r}
t$sum(dim = 2)
```

# Autograd



# Function Minimization

# Modules

# Optimizers

# Loss functions










# 4. Computer Vision in R mit Torchvision

## Bildklassifizierung mit Torch in R





Ein Prototyp eines convnet


Argumente von nn_convnet2d()


Argumente von pooling layers

Zooming out

Image classification
```{r}
library(torch)
library(torchvision)
library(luz)
```


```{r}
set.seed(777)
torch_manual_seed(777)

dir <- "~/.torch-datasets"

train_ds <- tiny_imagenet_dataset(
  dir,
  download = TRUE,
  transform = function(x) {
    x %>%
      transform_to_tensor() 
  }
)

valid_ds <- tiny_imagenet_dataset(
  dir,
  split = "val",
  transform = function(x) {
    x %>%
      transform_to_tensor()
  }
)
```



```{r}
train_dl <- dataloader(train_ds,
  batch_size = 128,
  shuffle = TRUE
)
valid_dl <- dataloader(valid_ds, batch_size = 128)


batch <- train_dl %>%
  dataloader_make_iter() %>%
  dataloader_next()

dim(batch$x)
```

```{r}
batch$y
```


Image classification from scratch
```{r}
convnet <- nn_module(
  "convnet",
  initialize = function() {
    self$features <- nn_sequential(
      nn_conv2d(3, 64, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_max_pool2d(kernel_size = 2),
      nn_conv2d(64, 128, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_max_pool2d(kernel_size = 2),
      nn_conv2d(128, 256, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_max_pool2d(kernel_size = 2),
      nn_conv2d(256, 512, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_max_pool2d(kernel_size = 2),
      nn_conv2d(512, 1024, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_adaptive_avg_pool2d(c(1, 1))
    )
    self$classifier <- nn_sequential(
      nn_linear(1024, 1024),
      nn_relu(),
      nn_linear(1024, 1024),
      nn_relu(),
      nn_linear(1024, 200)
    )
  },
  forward = function(x) {
    x <- self$features(x)$squeeze()
    x <- self$classifier(x)
    x
  }
)
```

```{r}
fitted <- convnet %>%
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_adam,
    metrics = list(
      luz_metric_accuracy()
    )
  ) %>%
  fit(train_dl,
      epochs = 1,
      valid_data = valid_dl,
      verbose = TRUE
      )
```
Dieser Codechunk kann lange dauert, mit den Epochen kann man es verkürzen.

```{r}
preds <- last %>% predict(valid_dl)
```

```{r}
torch_argmax(preds, dim = 2)
```



## Neural Networks with Torch in R
From: https://anderfernandez.com/en/blog/how-to-create-neural-networks-with-torch-in-r/
```{r}
#install.packages("torch")
#install.packages("(torchvision")
#install.packages("torchaudio")
#install.packages("luz")
library(torch)
library(torchvision)
```

```{r}
model = nn_sequential(

  # Layer 1
  nn_linear(4, 8),
  nn_relu(), 

  # Layer 2
  nn_linear(8, 16),
  nn_relu(),

  # Layee 3
  nn_linear(16,3),
  nn_softmax(2)
)
```


```{r}
net = nn_module(
  "class_net",

  initialize = function(){

    self$linear1 = nn_linear(4,8)
    self$linear2 = nn_linear(8,16)
    self$linear3 = nn_linear(16,3)

  },

  forward = function(x){

    x %>%
      self$linear1() %>%
      nnf_relu() %>%
      self$linear2() %>%
      nnf_relu() %>%
      self$linear3() %>%
      nnf_softmax(2)

  }

)

model2 = net()
```

```{r}
x = torch_randint(0,2,size = c(20,4)) # I create a tensor with random data

model2$forward(x)
```
```{r}
# 1.Split our data between train and test
train_split = 0.8
sample_indices =sample(nrow(iris) * train_split)

# 2. Convert our input data to matrices and labels to vectors.
x_train = as.matrix(iris[sample_indices, -5])
y_train = as.numeric(iris[sample_indices, 5])
x_test = as.matrix(iris[-sample_indices, -5])
y_test = as.numeric(iris[-sample_indices, 5])

# 3. Convert our input data and labels into tensors.
x_train = torch_tensor(x_train, dtype = torch_float())
y_train = torch_tensor(y_train, dtype = torch_long())
x_test = torch_tensor(x_test, dtype = torch_float())
y_test = torch_tensor(y_test, dtype = torch_long())
```


```{r}
pred_temp = model(x_train)
cat(
  " Dimensions Prediction: ", pred_temp$shape," - Object type Prediction: ", as.character(pred_temp$dtype), "\n",
  "Dimensions Label: ", y_train$shape," - Object type Label: ", as.character(y_train$dtype)
  )
```

```{r}
library(torchvision)
```

```{r}
library(magick)

url_imagen = "https://c.files.bbci.co.uk/48DD/production/_107435681_perro1.jpg"
imagen = image_read(url_imagen)

plot(imagen)
```
```{r}
img_width = image_info(imagen)$width
img_height = image_info(imagen)$height

imagen_crop = transform_crop(imagen,0,0, img_height/2, img_width/2)
imagen_crop_center = transform_center_crop(imagen, c(img_height/2, img_width/2))
imagen_resize = transform_resize(imagen, c(img_height/2, img_width/2))
imagen_flip = transform_hflip(imagen)

image_grid = c(imagen_crop, imagen_crop_center, 
               imagen_resize, imagen_flip)

geometry = geometry_area(400, 200)

image_montage(image_grid, tile = '2', geometry = geometry)
```
```{r}
# Download a preloaded dataset from torchvision
tiny_imagenet_dataset("images", download = T)

# Upload the images from the folder we just downloaded.
dataset = image_folder_dataset("images")

# Create the dataloader
imagenes_dataloader = dataloader(dataset , batch_size =  10, shuffle = T)

# Save batches
batch = imagenes_dataloader$.iter()$.next()

# Visualize the first batch size
batch[[1]]$size()
```

```{r}
optimizer$zero_grad()
```

```{r}
# We create the cost function and the optimizer
criterion = nn_cross_entropy_loss()  

# We calculate the error
loss = criterion(pred_temp, y_train)
loss
```

```{r}
optimizer = optim_adam(model$parameters)
```

```{r}
loss$backward()
```

```{r}
optimizer$step()
```

```{r}
# Define the network
model = nn_sequential(

  # Layer 1
  nn_linear(4, 8),
  nn_relu(), 

  # Layer 2
  nn_linear(8, 16),
  nn_relu(),

  # Layer 3
  nn_linear(16,3)
)

# Define cost and optimizer
criterion = nn_cross_entropy_loss()  
optimizer = optim_adam(model$parameters, lr = 0.01)

epochs = 200

# Train the net
for(i in 1:epochs){

  optimizer$zero_grad()

  y_pred = model(x_train)
  loss = criterion(y_pred, y_train)
  loss$backward()
  optimizer$step()


  # Check Training
  if(i %% 10 == 0){

    winners = y_pred$argmax(dim=2)+1
    corrects = (winners == y_train)
    accuracy = corrects$sum()$item() / y_train$size()

    cat(" Epoch:", i,"Loss: ", loss$item()," Accuracy:",accuracy,"\n")
  }

}
```

```{r}
model$eval()
```

```{r}
torch_save(model, "modelo.rt")
```

```{r}
modelo_cargado = torch_load("modelo.rt")
modelo_cargado
```

