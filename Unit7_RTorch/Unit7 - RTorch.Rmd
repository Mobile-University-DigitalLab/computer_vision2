---
title: "Unit 7 CNNs mit RTorch"
output: html_notebook
---

# Tensoren
Um mit Tensoren zu arbeiten, müssen Sie zunächst das Package installieren und laden:
```{r}
if (!require("torch")) install.packages("torch")
library(torch)
```

Erstellen Sie direkt Ihren ersten Tensor in Form einer Matrix:
```{r}
torch_tensor(matrix(1:9, ncol=3))
```

Sie können auch vordefinierte Tensoren erstellen:
```{r}
torch_eye(n =5)
```

Tensoren können aus Datensätzen erstellt werden:
```{r}
torch_tensor(JohnsonJohnson)
```

Gegebenenfalls müssen characters erst in Faktoren, dann Numerics überführt werden und daraus dann ein Tensor erstellt werden.


Sie können mit Tensoren rechnen
Addition
```{r}
t1 <- torch_tensor(c(1, 2))
t2 <- torch_tensor(c(3, 4))

torch_add(t1, t2)
```


Sie können Tensoren untersuchen und deren Eigenschaften bearbeiten:
```{r}
t2 <- t1$to(dtype = torch_int())
t2$dtype
```

Kreuzprodukt
```{r}
t1 <- torch_tensor(c(2,7,1))
t2 <- torch_tensor(c(8,2,8))
t1$dot(t2)
```

Matrixmultiplikation
```{r}
t1 <- torch_tensor(1:3)
t2 <- torch_tensor(4:6)
t3 <- torch_tensor(matrix(1:12, ncol = 3, byrow = TRUE))
t3$matmul(t1)
```

Skalarprodukt
```{r}
torch_multiply(t1, t2)
```

Schließlich können Sie Summary Operations benutzen. Sie können entweder die ganze Matrix oder nur Zeilen oder nur Spalten einbeziehen (Dimension)

```{r}
t <- torch_outer(torch_tensor(1:3), torch_tensor(1:6))
t$sum()
```

```{r}
t$sum(dim = 1)
```

```{r}
t$sum(dim = 2)
```


# Bildklassifizierung mit Torch in R - Beispiel 1
Aus: Keydana, 2020

```{r}
library(torch)
library(torchvision)
library(luz)
```


```{r}
set.seed(777)
torch_manual_seed(777)

dir <- "~/.torch-datasets"

train_ds <- tiny_imagenet_dataset(
  dir,
  download = TRUE,
  transform = function(x) {
    x %>%
      transform_to_tensor() 
  }
)

valid_ds <- tiny_imagenet_dataset(
  dir,
  split = "val",
  transform = function(x) {
    x %>%
      transform_to_tensor()
  }
)
```


```{r}
train_dl <- dataloader(train_ds,
  batch_size = 128,
  shuffle = TRUE
)
valid_dl <- dataloader(valid_ds, batch_size = 128)


batch <- train_dl %>%
  dataloader_make_iter() %>%
  dataloader_next()

dim(batch$x)
```

```{r}
batch$y
```

```{r}
convnet <- nn_module(
  "convnet",
  initialize = function() {
    self$features <- nn_sequential(
      nn_conv2d(3, 64, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_max_pool2d(kernel_size = 2),
      nn_conv2d(64, 128, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_max_pool2d(kernel_size = 2),
      nn_conv2d(128, 256, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_max_pool2d(kernel_size = 2),
      nn_conv2d(256, 512, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_max_pool2d(kernel_size = 2),
      nn_conv2d(512, 1024, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_adaptive_avg_pool2d(c(1, 1))
    )
    self$classifier <- nn_sequential(
      nn_linear(1024, 1024),
      nn_relu(),
      nn_linear(1024, 1024),
      nn_relu(),
      nn_linear(1024, 200)
    )
  },
  forward = function(x) {
    x <- self$features(x)$squeeze()
    x <- self$classifier(x)
    x
  }
)
```

```{r}
fitted <- convnet %>%
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_adam,
    metrics = list(
      luz_metric_accuracy()
    )
  ) %>%
  fit(train_dl,
      epochs = 1,
      valid_data = valid_dl,
      verbose = TRUE
      )
```
Dieser Codechunk kann lange dauern, mit den Epochen kann man es verkürzen.

```{r}
preds <- last %>% predict(valid_dl)
```

```{r}
torch_argmax(preds, dim = 2)
```


# Bildklassifizierung mit Torch in R - Beispiel 2


```{r}
# deep learning (incl. dependencies)
library(torch)
library(torchvision)

# data wrangling
library(tidyverse)
library(zeallot)

# image processing and visualization
library(magick)
library(cowplot)

# dataset loading 
library(pins)
library(zip)

torch_manual_seed(777)
set.seed(777)

# use your own kaggle.json here
#pins::board_register_kaggle(token = "~/kaggle.json")

files <- pins::pin_get("mateuszbuda/lgg-mri-segmentation", board = "kaggle",  extract = FALSE)
```

```{r}
setwd("C:/Users/PrinzDrChristian(SRH/OneDrive - SRH Fernhochschule/Dokumente/R/torchbrainsegmentationdata/data")
```




```{r}
train_dir <- "data/mri_train"
valid_dir <- "data/mri_valid"

if(dir.exists(train_dir)) unlink(train_dir, recursive = TRUE, force = TRUE)
if(dir.exists(valid_dir)) unlink(valid_dir, recursive = TRUE, force = TRUE)

zip::unzip(files, exdir = "data")

file.rename("data/kaggle_3m", train_dir)

# this is a duplicate, again containing kaggle_3m (evidently a packaging error on Kaggle)
# we just remove it
unlink("data/lgg-mri-segmentation", recursive = TRUE)

dir.create(valid_dir)
```

```{r}
valid_indices <- sample(1:length(patients), 30)

patients <- list.dirs(train_dir, recursive = FALSE)

for (i in valid_indices) {
  dir.create(file.path(valid_dir, basename(patients[i])))
  for (f in list.files(patients[i])) {    
    file.rename(file.path(train_dir, basename(patients[i]), f), file.path(valid_dir, basename(patients[i]), f))    
  }
  unlink(file.path(train_dir, basename(patients[i])), recursive = TRUE)
}
```

