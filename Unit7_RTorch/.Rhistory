if (!require("torch")) install.packages("torch")
library(torch)
torch_tensor(matrix(1:9, ncol=3))
t2 <- t1$to(dtype = torch_int())
t1 <- t1$to(dtype = torch_int())
torch_eye(n =5)
torch_tensor(JohnsonJohnson)
t1 <- torch_tensor(c(1, 2))
t2 <- torch_tensor(c(3, 4))
torch_add(t1, t2)
t2 <- t1$to(dtype = torch_int())
t2$dtype
t1 <- torch_tensor(c(2,7,1))
t2 <- torch_tensor(c(8,2,8))
t1$dot(t2)
t1 <- torch_tensor(1:3)
t2 <- torch_tensor(4:6)
t3 <- torch_tensor(matrix(1:12, ncol = 3, byrow = TRUE))
t3$matmul(t1)
torch_multiply(t1, t2)
t <- torch_outer(torch_tensor(1:3), torch_tensor(1:6))
t$sum()
t$sum(dim = 1)
t$sum(dim = 2)
library(torch)
library(torchvision)
library(luz)
set.seed(777)
torch_manual_seed(777)
dir <- "~/.torch-datasets"
train_ds <- tiny_imagenet_dataset(
dir,
download = TRUE,
transform = function(x) {
x %>%
transform_to_tensor()
}
)
valid_ds <- tiny_imagenet_dataset(
dir,
split = "val",
transform = function(x) {
x %>%
transform_to_tensor()
}
)
train_dl <- dataloader(train_ds,
batch_size = 128,
shuffle = TRUE
)
valid_dl <- dataloader(valid_ds, batch_size = 128)
batch <- train_dl %>%
dataloader_make_iter() %>%
dataloader_next()
dim(batch$x)
batch$y
convnet <- nn_module(
"convnet",
initialize = function() {
self$features <- nn_sequential(
nn_conv2d(3, 64, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(64, 128, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(128, 256, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(256, 512, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(512, 1024, kernel_size = 3, padding = 1),
nn_relu(),
nn_adaptive_avg_pool2d(c(1, 1))
)
self$classifier <- nn_sequential(
nn_linear(1024, 1024),
nn_relu(),
nn_linear(1024, 1024),
nn_relu(),
nn_linear(1024, 200)
)
},
forward = function(x) {
x <- self$features(x)$squeeze()
x <- self$classifier(x)
x
}
)
fitted <- convnet %>%
setup(
loss = nn_cross_entropy_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
fit(train_dl,
epochs = 1,
valid_data = valid_dl,
verbose = TRUE
)
#install.packages("torch")
#install.packages("(torchvision")
#install.packages("torchaudio")
#install.packages("luz")
library(torch)
library(torchvision)
model = nn_sequential(
# Layer 1
nn_linear(4, 8),
nn_relu(),
# Layer 2
nn_linear(8, 16),
nn_relu(),
# Layee 3
nn_linear(16,3),
nn_softmax(2)
)
net = nn_module(
"class_net",
initialize = function(){
self$linear1 = nn_linear(4,8)
self$linear2 = nn_linear(8,16)
self$linear3 = nn_linear(16,3)
},
forward = function(x){
x %>%
self$linear1() %>%
nnf_relu() %>%
self$linear2() %>%
nnf_relu() %>%
self$linear3() %>%
nnf_softmax(2)
}
)
model2 = net()
x = torch_randint(0,2,size = c(20,4)) # I create a tensor with random data
model2$forward(x)
# 1.Split our data between train and test
train_split = 0.8
sample_indices =sample(nrow(iris) * train_split)
# 2. Convert our input data to matrices and labels to vectors.
x_train = as.matrix(iris[sample_indices, -5])
y_train = as.numeric(iris[sample_indices, 5])
x_test = as.matrix(iris[-sample_indices, -5])
y_test = as.numeric(iris[-sample_indices, 5])
# 3. Convert our input data and labels into tensors.
x_train = torch_tensor(x_train, dtype = torch_float())
y_train = torch_tensor(y_train, dtype = torch_long())
x_test = torch_tensor(x_test, dtype = torch_float())
y_test = torch_tensor(y_test, dtype = torch_long())
pred_temp = model(x_train)
cat(
" Dimensions Prediction: ", pred_temp$shape," - Object type Prediction: ", as.character(pred_temp$dtype), "\n",
"Dimensions Label: ", y_train$shape," - Object type Label: ", as.character(y_train$dtype)
)
library(torchvision)
library(magick)
url_imagen = "https://c.files.bbci.co.uk/48DD/production/_107435681_perro1.jpg"
imagen = image_read(url_imagen)
plot(imagen)
img_width = image_info(imagen)$width
img_height = image_info(imagen)$height
imagen_crop = transform_crop(imagen,0,0, img_height/2, img_width/2)
imagen_crop_center = transform_center_crop(imagen, c(img_height/2, img_width/2))
imagen_resize = transform_resize(imagen, c(img_height/2, img_width/2))
imagen_flip = transform_hflip(imagen)
image_grid = c(imagen_crop, imagen_crop_center,
imagen_resize, imagen_flip)
geometry = geometry_area(400, 200)
image_montage(image_grid, tile = '2', geometry = geometry)
# Download a preloaded dataset from torchvision
tiny_imagenet_dataset("images", download = T)
# Upload the images from the folder we just downloaded.
dataset = image_folder_dataset("images")
# Create the dataloader
imagenes_dataloader = dataloader(dataset , batch_size =  10, shuffle = T)
# Save batches
batch = imagenes_dataloader$.iter()$.next()
# Visualize the first batch size
batch[[1]]$size()
optimizer$zero_grad()
optimizer$zero_grad()
#install.packages("torch")
#install.packages("(torchvision")
#install.packages("torchaudio")
#install.packages("luz")
library(torch)
library(torchvision)
model = nn_sequential(
# Layer 1
nn_linear(4, 8),
nn_relu(),
# Layer 2
nn_linear(8, 16),
nn_relu(),
# Layee 3
nn_linear(16,3),
nn_softmax(2)
)
net = nn_module(
"class_net",
initialize = function(){
self$linear1 = nn_linear(4,8)
self$linear2 = nn_linear(8,16)
self$linear3 = nn_linear(16,3)
},
forward = function(x){
x %>%
self$linear1() %>%
nnf_relu() %>%
self$linear2() %>%
nnf_relu() %>%
self$linear3() %>%
nnf_softmax(2)
}
)
model2 = net()
x = torch_randint(0,2,size = c(20,4)) # I create a tensor with random data
model2$forward(x)
# 1.Split our data between train and test
train_split = 0.8
sample_indices =sample(nrow(iris) * train_split)
# 2. Convert our input data to matrices and labels to vectors.
x_train = as.matrix(iris[sample_indices, -5])
y_train = as.numeric(iris[sample_indices, 5])
x_test = as.matrix(iris[-sample_indices, -5])
y_test = as.numeric(iris[-sample_indices, 5])
# 3. Convert our input data and labels into tensors.
x_train = torch_tensor(x_train, dtype = torch_float())
y_train = torch_tensor(y_train, dtype = torch_long())
x_test = torch_tensor(x_test, dtype = torch_float())
y_test = torch_tensor(y_test, dtype = torch_long())
pred_temp = model(x_train)
cat(
" Dimensions Prediction: ", pred_temp$shape," - Object type Prediction: ", as.character(pred_temp$dtype), "\n",
"Dimensions Label: ", y_train$shape," - Object type Label: ", as.character(y_train$dtype)
)
library(torchvision)
library(magick)
url_imagen = "https://c.files.bbci.co.uk/48DD/production/_107435681_perro1.jpg"
imagen = image_read(url_imagen)
plot(imagen)
img_width = image_info(imagen)$width
img_height = image_info(imagen)$height
imagen_crop = transform_crop(imagen,0,0, img_height/2, img_width/2)
imagen_crop_center = transform_center_crop(imagen, c(img_height/2, img_width/2))
imagen_resize = transform_resize(imagen, c(img_height/2, img_width/2))
imagen_flip = transform_hflip(imagen)
image_grid = c(imagen_crop, imagen_crop_center,
imagen_resize, imagen_flip)
geometry = geometry_area(400, 200)
image_montage(image_grid, tile = '2', geometry = geometry)
# Download a preloaded dataset from torchvision
tiny_imagenet_dataset("images", download = T)
# Upload the images from the folder we just downloaded.
dataset = image_folder_dataset("images")
# Create the dataloader
imagenes_dataloader = dataloader(dataset , batch_size =  10, shuffle = T)
# Save batches
batch = imagenes_dataloader$.iter()$.next()
# Visualize the first batch size
batch[[1]]$size()
optimizer$zero_grad()
# We create the cost function and the optimizer
criterion = nn_cross_entropy_loss()
# We calculate the error
loss = criterion(pred_temp, y_train)
loss
optimizer = optim_adam(model$parameters)
loss$backward()
optimizer$step()
# Define the network
model = nn_sequential(
# Layer 1
nn_linear(4, 8),
nn_relu(),
# Layer 2
nn_linear(8, 16),
nn_relu(),
# Layer 3
nn_linear(16,3)
)
# Define cost and optimizer
criterion = nn_cross_entropy_loss()
optimizer = optim_adam(model$parameters, lr = 0.01)
epochs = 200
# Train the net
for(i in 1:epochs){
optimizer$zero_grad()
y_pred = model(x_train)
loss = criterion(y_pred, y_train)
loss$backward()
optimizer$step()
# Check Training
if(i %% 10 == 0){
winners = y_pred$argmax(dim=2)+1
corrects = (winners == y_train)
accuracy = corrects$sum()$item() / y_train$size()
cat(" Epoch:", i,"Loss: ", loss$item()," Accuracy:",accuracy,"\n")
}
}
model$eval()
if (!require("torch")) install.packages("torch")
library(torch)
torch_tensor(matrix(1:9, ncol=3))
torch_eye(n =5)
torch_tensor(JohnsonJohnson)
t1 <- torch_tensor(c(1, 2))
t2 <- torch_tensor(c(3, 4))
torch_add(t1, t2)
t2 <- t1$to(dtype = torch_int())
t2$dtype
t1 <- torch_tensor(c(2,7,1))
t2 <- torch_tensor(c(8,2,8))
t1$dot(t2)
t1 <- torch_tensor(1:3)
t2 <- torch_tensor(4:6)
t3 <- torch_tensor(matrix(1:12, ncol = 3, byrow = TRUE))
t3$matmul(t1)
torch_multiply(t1, t2)
t <- torch_outer(torch_tensor(1:3), torch_tensor(1:6))
t$sum()
t$sum(dim = 1)
t$sum(dim = 2)
library(torch)
library(torchvision)
library(luz)
set.seed(777)
torch_manual_seed(777)
dir <- "~/.torch-datasets"
train_ds <- tiny_imagenet_dataset(
dir,
download = TRUE,
transform = function(x) {
x %>%
transform_to_tensor()
}
)
valid_ds <- tiny_imagenet_dataset(
dir,
split = "val",
transform = function(x) {
x %>%
transform_to_tensor()
}
)
train_dl <- dataloader(train_ds,
batch_size = 128,
shuffle = TRUE
)
valid_dl <- dataloader(valid_ds, batch_size = 128)
batch <- train_dl %>%
dataloader_make_iter() %>%
dataloader_next()
dim(batch$x)
batch$y
convnet <- nn_module(
"convnet",
initialize = function() {
self$features <- nn_sequential(
nn_conv2d(3, 64, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(64, 128, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(128, 256, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(256, 512, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(512, 1024, kernel_size = 3, padding = 1),
nn_relu(),
nn_adaptive_avg_pool2d(c(1, 1))
)
self$classifier <- nn_sequential(
nn_linear(1024, 1024),
nn_relu(),
nn_linear(1024, 1024),
nn_relu(),
nn_linear(1024, 200)
)
},
forward = function(x) {
x <- self$features(x)$squeeze()
x <- self$classifier(x)
x
}
)
fitted <- convnet %>%
setup(
loss = nn_cross_entropy_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
fit(train_dl,
epochs = 1,
valid_data = valid_dl,
verbose = TRUE
)
preds <- last %>% predict(valid_dl)
if (!require("torch")) install.packages("torch")
library(torch)
torch_tensor(matrix(1:9, ncol=3))
torch_eye(n =5)
torch_tensor(JohnsonJohnson)
t1 <- torch_tensor(c(1, 2))
t2 <- torch_tensor(c(3, 4))
torch_add(t1, t2)
t2 <- t1$to(dtype = torch_int())
t2$dtype
t1 <- torch_tensor(c(2,7,1))
t2 <- torch_tensor(c(8,2,8))
t1$dot(t2)
t1 <- torch_tensor(1:3)
t2 <- torch_tensor(4:6)
t3 <- torch_tensor(matrix(1:12, ncol = 3, byrow = TRUE))
t3$matmul(t1)
torch_multiply(t1, t2)
t <- torch_outer(torch_tensor(1:3), torch_tensor(1:6))
t$sum()
t$sum(dim = 1)
t$sum(dim = 2)
library(torch)
library(torchvision)
library(luz)
set.seed(777)
torch_manual_seed(777)
dir <- "~/.torch-datasets"
train_ds <- tiny_imagenet_dataset(
dir,
download = TRUE,
transform = function(x) {
x %>%
transform_to_tensor()
}
)
valid_ds <- tiny_imagenet_dataset(
dir,
split = "val",
transform = function(x) {
x %>%
transform_to_tensor()
}
)
train_dl <- dataloader(train_ds,
batch_size = 128,
shuffle = TRUE
)
valid_dl <- dataloader(valid_ds, batch_size = 128)
batch <- train_dl %>%
dataloader_make_iter() %>%
dataloader_next()
dim(batch$x)
batch$y
convnet <- nn_module(
"convnet",
initialize = function() {
self$features <- nn_sequential(
nn_conv2d(3, 64, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(64, 128, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(128, 256, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(256, 512, kernel_size = 3, padding = 1),
nn_relu(),
nn_max_pool2d(kernel_size = 2),
nn_conv2d(512, 1024, kernel_size = 3, padding = 1),
nn_relu(),
nn_adaptive_avg_pool2d(c(1, 1))
)
self$classifier <- nn_sequential(
nn_linear(1024, 1024),
nn_relu(),
nn_linear(1024, 1024),
nn_relu(),
nn_linear(1024, 200)
)
},
forward = function(x) {
x <- self$features(x)$squeeze()
x <- self$classifier(x)
x
}
)
fitted <- convnet %>%
setup(
loss = nn_cross_entropy_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
fit(train_dl,
epochs = 1,
valid_data = valid_dl,
verbose = TRUE
)
preds <- last %>% predict(valid_dl)
preds <- last %>% predict(valid_dl)
